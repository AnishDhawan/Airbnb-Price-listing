{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding up packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.linear_model as slm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the dataset\n",
    "data = pd.read_csv('airbnb-seattle-listings-train.csv', sep='\\t')\n",
    "\n",
    "# 1.1 Describing the dataset\n",
    "# As we can see there are 7540 rows and 106 columns in the dataset. most of them are non-numerical data, such as \n",
    "# description of the facilitry, a short summary of the apartment, and boolean values on things such as if you can\n",
    "# smoke in the room. \n",
    "# most of them, we consider, will be not useful for making a predictive model and we will use be selective on what\n",
    "# variables to use. However, some of the qualitative variables are useful, like house-type, and neighborhood type.\n",
    "# To take them into our model, we need to manipulate the dataset. Turning some non-numerical values into 0/1 representation\n",
    "# or the grouped mean using group method. \n",
    "\n",
    "# 1.2 Missing data\n",
    "# Missing data in the set comes in different forms and dropna() is not always useful.\n",
    "# In training our model we draw a board line on missing percentage. If more then 20% of the data is missing, we\n",
    "# will avoid to use such variables in our regression. For the data that is missing, we remove the row with the\n",
    "# selected variable in the regression who has >20% data missing.\n",
    "\n",
    "# 1.3 \n",
    "# For example, we use security_desposit in the full model. we think it carries information on the housing price. \n",
    "# we will talk more into it when working on regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# we split our dataset into train/test subsets.\n",
    "# np.random.seed(1)\n",
    "# train, test = train_test_split(data, test_size=0.25)\n",
    "# we will split after we cleaning up the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 \n",
    "# cleaning/ filter the dataset\n",
    "# converting house price string to float point\n",
    "data['price'] = [re.sub('[$,]', '', str(x)) for x in data['price']]\n",
    "\n",
    "# converting security deposit to float point\n",
    "data['security_deposit'] = [re.sub('[$,]', '', str(x)) for x in data['security_deposit']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['cleaning_fee'] = [re.sub('[$,]', '', str(x)) for x in data['cleaning_fee']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['weekly_price'] = [re.sub('[$,]', '', str(x)) for x in data['weekly_price']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['monthly_price'] = [re.sub('[$,]', '', str(x)) for x in data['monthly_price']]\n",
    "\n",
    "# converting require license to float point\n",
    "data['requires_license'] = data['requires_license']\n",
    "data['requires_license'].replace('f', 0, inplace=True)\n",
    "data['requires_license'].replace('t', 1, inplace=True)\n",
    "\n",
    "# # split the dataset into two subsets\n",
    "np.random.seed(1)\n",
    "train, test = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.439\n",
      "Model:                            OLS   Adj. R-squared:                  0.437\n",
      "Method:                 Least Squares   F-statistic:                     168.2\n",
      "Date:                Thu, 05 Dec 2019   Prob (F-statistic):           1.17e-54\n",
      "Time:                        19:08:57   Log-Likelihood:                -2536.1\n",
      "No. Observations:                 432   AIC:                             5078.\n",
      "Df Residuals:                     429   BIC:                             5090.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            43.7677      6.081      7.198      0.000      31.816      55.719\n",
      "weekly_price      0.1705      0.023      7.352      0.000       0.125       0.216\n",
      "monthly_price    -0.0194      0.007     -2.959      0.003      -0.032      -0.007\n",
      "==============================================================================\n",
      "Omnibus:                      355.051   Durbin-Watson:                   2.053\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            37488.074\n",
      "Skew:                           2.783   Prob(JB):                         0.00\n",
      "Kurtosis:                      48.296   Cond. No.                     5.45e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.45e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "51.04341637058881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# two variable model \n",
    "# selecting a subset of table, making it easier to make regression\n",
    "df = train[['price','weekly_price', 'monthly_price']]\n",
    "df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "x = df[['weekly_price', 'monthly_price']]\n",
    "x = sm.add_constant(x)\n",
    "y = df.price\n",
    "\n",
    "# make a regression using statsmodel\n",
    "mod = sm.OLS(y, x)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "# compute the rmse using sklearn\n",
    "m = slm.LinearRegression().fit(x, y)\n",
    "df_2 = test[['price','weekly_price', 'monthly_price']]\n",
    "df_2 = df_2.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "y_test = df_2.price\n",
    "x_test = df_2[['weekly_price', 'monthly_price']]\n",
    "x_test = sm.add_constant(x_test)\n",
    "yhat = m.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((yhat - y_test)**2))\n",
    "\n",
    "# print out the sklearn rmse.\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.556\n",
      "Model:                            OLS   Adj. R-squared:                  0.543\n",
      "Method:                 Least Squares   F-statistic:                     44.19\n",
      "Date:                Thu, 05 Dec 2019   Prob (F-statistic):           1.10e-61\n",
      "Time:                        19:13:22   Log-Likelihood:                -2298.4\n",
      "No. Observations:                 400   AIC:                             4621.\n",
      "Df Residuals:                     388   BIC:                             4669.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "accommodates               6.9642      3.858      1.805      0.072      -0.622      14.550\n",
      "bathrooms                  8.8640      6.334      1.399      0.162      -3.589      21.317\n",
      "bedrooms                  26.7075      7.490      3.566      0.000      11.981      41.434\n",
      "beds                       2.1710      6.642      0.327      0.744     -10.888      15.230\n",
      "weekly_price               0.1024      0.023      4.401      0.000       0.057       0.148\n",
      "monthly_price             -0.0125      0.006     -2.000      0.046      -0.025      -0.000\n",
      "reviews_per_month          0.1087      2.676      0.041      0.968      -5.153       5.370\n",
      "requires_license        -115.3833     78.724     -1.466      0.144    -270.163      39.396\n",
      "review_scores_location   -10.9121      9.079     -1.202      0.230     -28.762       6.938\n",
      "review_scores_accuracy    -7.7507     11.379     -0.681      0.496     -30.124      14.622\n",
      "review_scores_rating       3.0435      1.259      2.418      0.016       0.569       5.518\n",
      "cleaning_fee               0.1844      0.090      2.039      0.042       0.007       0.362\n",
      "==============================================================================\n",
      "Omnibus:                      403.370   Durbin-Watson:                   2.070\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            30050.344\n",
      "Skew:                           4.078   Prob(JB):                         0.00\n",
      "Kurtosis:                      44.671   Cond. No.                     7.72e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.72e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "51.61280855643217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# making a regression using everything we think is important.\n",
    "df = train[['price','accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# transform the y value: remove dollar sign and convert it to float point data type\n",
    "x = df[['accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "x = sm.add_constant(x)\n",
    "y = df.price\n",
    "\n",
    "# make a regression using statsmodel\n",
    "mod = sm.OLS(y, x)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "# computing the rmse using sklearn package\n",
    "m_full= slm.LinearRegression().fit(x, y)\n",
    "df_3 = test[['price','accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "df_3 = df_3.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "y_test = df_3.price\n",
    "x_test = df_3[['accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "x_test = sm.add_constant(x_test)\n",
    "yhat = m_full.predict(x_test)\n",
    "\n",
    "rmse = np.sqrt(np.mean((yhat - y_test)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In between regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.246\n",
      "Model:                            OLS   Adj. R-squared:                  0.238\n",
      "Method:                 Least Squares   F-statistic:                     29.16\n",
      "Date:                Thu, 05 Dec 2019   Prob (F-statistic):           3.01e-30\n",
      "Time:                        19:08:58   Log-Likelihood:                -3456.4\n",
      "No. Observations:                 542   AIC:                             6927.\n",
      "Df Residuals:                     535   BIC:                             6957.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                   -105.1464    115.171     -0.913      0.362    -331.390     121.097\n",
      "accommodates               5.7253      4.851      1.180      0.238      -3.804      15.254\n",
      "bedrooms                  25.8278     11.032      2.341      0.020       4.156      47.499\n",
      "weekly_price               0.0681      0.012      5.544      0.000       0.044       0.092\n",
      "review_scores_location    13.1981     11.954      1.104      0.270     -10.284      36.680\n",
      "cleaning_fee               0.1571      0.145      1.084      0.279      -0.128       0.442\n",
      "number_of_reviews         -0.0776      0.067     -1.152      0.250      -0.210       0.055\n",
      "==============================================================================\n",
      "Omnibus:                     1137.272   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2175750.098\n",
      "Skew:                          15.641   Prob(JB):                         0.00\n",
      "Kurtosis:                     311.812   Cond. No.                     1.98e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.98e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "46.00994512743368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# making a regression using somewhat in between. \n",
    "# selecting a subset of dataset\n",
    "df = train[['price','accommodates','bedrooms', 'weekly_price', 'review_scores_location', \n",
    "            'cleaning_fee', 'number_of_reviews']]\n",
    "df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# defining x and y value\n",
    "x = df[['accommodates','bedrooms', 'weekly_price', 'review_scores_location', \n",
    "            'cleaning_fee', 'number_of_reviews']]\n",
    "x = sm.add_constant(x)\n",
    "y = df.price\n",
    "\n",
    "# make a regression using statsmodel\n",
    "mod = sm.OLS(y, x)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "# computing the rmse using sklearn package\n",
    "m = slm.LinearRegression().fit(x, y)\n",
    "df_3 = test[['price','accommodates','bedrooms', 'weekly_price', 'review_scores_location', \n",
    "            'cleaning_fee', 'number_of_reviews']]\n",
    "df_3 = df_3.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "y_test = df_3.price\n",
    "x_test = df_3[['accommodates','bedrooms', 'weekly_price', 'review_scores_location', \n",
    "            'cleaning_fee', 'number_of_reviews']]\n",
    "x_test = sm.add_constant(x_test)\n",
    "yhat = m.predict(x_test)\n",
    "\n",
    "rmse = np.sqrt(np.mean((yhat - y_test)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the result\n",
    "\n",
    "#### simple regression \n",
    ">df = train[['price','weekly_price', 'monthly_price']]\n",
    "\n",
    "For our simple regression model, the coefficients were relatively tiny, at 0.1705 and -0.0194 for weekly_price and monthly_price, respectively. This indicated that these coefficients had a very small affect on the final predicted price, and that this model was perhaps not very accurate. \n",
    "\n",
    "#### full regression\n",
    "> df = train[['price','accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "            \n",
    "In our full regression model, the largest coefficient was for the bedrooms variable, which was the number of bedrooms available in the AirBnb, and had a value of 26.075. This means that this had the largest positive impact on price in our model. The lowest value was of the requires license variable, which had a value of -115. This meant that this had the highest impact of all the coefficients used, and would make the predicted value drastically lower. Some possible reasons for this could be that AirBnbs that attract lower income buyers may be more self conscious about their customers, and would want to screen them for safety and legal reasons. When comparing our full and in between regression models, there was definitely a discrepancy between the coefficient values. This could be explained by the fact that as a model takes into account more variables, it adjusts the impact that individual variables have on the final predicted price. Some more interesting observations in our full regression model was that the bedrooms and bathrooms had the highest coefficients, which could possibly be explained by how larger properties tend to have more bedrooms and bathrooms, and the larger the property the higher the cost it would be to rent. \n",
    "\n",
    "#### in-between regression \n",
    "we use part of the variables we used in full model in the third model. Those are variables we think are strong\n",
    "indicators of the daily housing price. \n",
    "\n",
    "> test[['price','accommodates','bedrooms', 'weekly_price', 'review_scores_location', \n",
    "            'cleaning_fee', 'number_of_reviews']]\n",
    "            \n",
    "the y intercept is -105.1464, that means when all independent variables are zero the y value, housing price, would be -105.1464. Although it seems irrelistic, some of the variables are qualitative data and we have to transform them into numerical values. This transformation can affect the intercept value.The strongest variable we have is 'bedrooms' which has coefficent of 25.8278. review_scores_location has coefficent of 13.1981. That observations fit in our common sense. We think location and number of rooms the property have can strongly influence the price. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Think\n",
    "\n",
    "1.Does your model do a good job in predicting the prices?\n",
    "\n",
    "Since no model can be absolutely perfect, it is quite difficult to create a model that captures every single attribute of any dataset. Regardless, we notice that our model does a good job in predicting the prices. With a pretty high confidence, our model shows a consistent prediction capability.  \n",
    " \n",
    "2.how will your model be useful to\n",
    "\n",
    "(a)\tAirBnB hosts – it can help hosts to model their houses in such a way that, it particularly solves a issue in their neighborhood. If a host sees a gap in their area, they can work efficiently using the model to create value for the customers.  \n",
    "\n",
    "(b) AirBnB customers – Customers can use our model to predict and plan their budgets, it is can be excellent tool to help customers understand how they can get the most back for their buck.\n",
    "\n",
    "3.Did you include any other price-related variables, such as _weekly price_ or _security deposit_ in your model? Do you think it is a good idea to use these attributes while trying to predict price?\n",
    "\n",
    "Through our models we realized that _security deposit_ is not a good indicator in our model. Because it disrupts the other values and their consistencies. The weekly price, according to our model is also not a good indicator of the model.\n",
    "  \n",
    "4.Do you think this model can be used by Airbnb itself or the government?\n",
    "\n",
    "Airbnb being a for-profit organization, it would be much more valuable for them to take over this model. The government on the other hand can use this model in their social programs to take the biggest challenges they face.   \n",
    "\n",
    "5.Do you see any ethical issues with this work?\n",
    "Although this model utilizes personal information from a lot of people, when used ethically the positives of using this model outweighs the negatives. Anyone using this model has to be trained in ethics so they understand the value of the information being used in the model and be responsible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Additional Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.32714310548417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# loading up the dataset\n",
    "data = pd.read_csv('airbnb-seattle-listings-test.csv', sep='\\t')\n",
    "\n",
    "# cleaning the dataset\n",
    "\n",
    "# converting house price string to float point\n",
    "data['price'] = [re.sub('[$,]', '', str(x)) for x in data['price']]\n",
    "\n",
    "# converting security deposit to float point\n",
    "data['security_deposit'] = [re.sub('[$,]', '', str(x)) for x in data['security_deposit']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['cleaning_fee'] = [re.sub('[$,]', '', str(x)) for x in data['cleaning_fee']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['weekly_price'] = [re.sub('[$,]', '', str(x)) for x in data['weekly_price']]\n",
    "\n",
    "# converting cleaning fee to float point\n",
    "data['monthly_price'] = [re.sub('[$,]', '', str(x)) for x in data['monthly_price']]\n",
    "\n",
    "# converting require license to float point\n",
    "data['requires_license'] = data['requires_license']\n",
    "data['requires_license'].replace('f', 0, inplace=True)\n",
    "data['requires_license'].replace('t', 1, inplace=True)\n",
    "\n",
    "# loading up the test set\n",
    "df_4 = data[['price','accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "\n",
    "df_4 = df_4.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# defining x and y\n",
    "y_test = df_4.price\n",
    "x_test = df_4[['accommodates','bathrooms','bedrooms','beds', 'weekly_price', 'monthly_price',\n",
    "            'reviews_per_month', 'requires_license', 'review_scores_location', 'review_scores_accuracy',\n",
    "            'review_scores_rating', 'cleaning_fee']]\n",
    "x_test = sm.add_constant(x_test)\n",
    "\n",
    "# computing yhat\n",
    "yhat = m_full.predict(x_test)\n",
    "\n",
    "# computing rmse\n",
    "rmse = np.sqrt(np.mean((yhat - y_test)**2))\n",
    "print(rmse)\n",
    "# we get rmse of 46.32714310548417."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
